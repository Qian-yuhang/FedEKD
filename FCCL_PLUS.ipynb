{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np   \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from utils.sampling import partition_public, partition_data_dataset\n",
    "from utils.options import args_parser\n",
    "from models.Update import DatasetSplit\n",
    "from models.test import test_img\n",
    "from models.resnet_client import resnet20, resnet16, resnet8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # parse args\n",
    "    args = args_parser(args=['--dataset','fashionmnist', '--momentum','0.9', '--alpha','1',\n",
    "                             '--epochs','50', '--gpu','0', '--public_data_ratio','0.1', '--lr','0.01'])\n",
    "\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "    print('torch.cuda:',torch.cuda.is_available())\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and split users\n",
    "if __name__ == '__main__':\n",
    "    if args.dataset == 'mnist':\n",
    "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda img: img.expand(3, -1, -1)), \n",
    "                                                    transforms.Normalize((0.1307,0.1307,0.1307), (0.3081,0.3081,0.3081))])\n",
    "        dataset_train = datasets.MNIST('data/mnist/', train = True, download = False, transform = trans_mnist)\n",
    "        dataset_test = datasets.MNIST('data/mnist/', train = False, download = False, transform = trans_mnist)\n",
    "\n",
    "        dataset_train, dataset_public = partition_public(dataset_train, args.public_data_ratio)\n",
    "        print('len(dataset_public): ', len(dataset_public))\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "    elif args.dataset == 'fashionmnist':\n",
    "        trans_fashionmnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda img: img.expand(3, -1, -1)), \n",
    "                                                    transforms.Normalize((0.1307,0.1307,0.1307), (0.3081,0.3081,0.3081))])\n",
    "        dataset_train = datasets.FashionMNIST('data/fashionmnist/', train = True, download = False, transform = trans_fashionmnist)\n",
    "        dataset_test = datasets.FashionMNIST('data/fashionmnist/', train = False, download = False, transform = trans_fashionmnist)\n",
    "    \n",
    "        dataset_train, dataset_public = partition_public(dataset_train, args.public_data_ratio)\n",
    "        print('len(dataset_public): ', len(dataset_public))\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "    elif args.dataset == 'cifar':\n",
    "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        dataset_train = datasets.CIFAR10('data/cifar', train = True, download = False, transform = trans_cifar)\n",
    "        dataset_test = datasets.CIFAR10('data/cifar', train = False, download = False, transform = trans_cifar)\n",
    "\n",
    "        dataset_train, dataset_public = partition_public(dataset_train, args.public_data_ratio)\n",
    "        print('len(dataset_public): ', len(dataset_public))\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "\n",
    "    elif args.dataset == 'cinic':\n",
    "        cinic_mean = [0.47889522, 0.47227842, 0.43047404]\n",
    "        cinic_std = [0.24205776, 0.23828046, 0.25874835]\n",
    "        transform_cinic = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cinic_mean, std=cinic_std)\n",
    "        ])\n",
    "        cinic_directory = 'data/cinic'\n",
    "        dataset_train = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'train'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_valid = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'valid'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_test = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'test'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_train = torch.utils.data.ConcatDataset([dataset_train, dataset_valid])\n",
    "\n",
    "        dataset_train, dataset_public = partition_public(dataset_train, args.public_data_ratio)\n",
    "        print('len(dataset_public): ', len(dataset_public))\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "\n",
    "    print(\"num_users:\", len(dict_users))\n",
    "    img_size = dataset_train[0][0].shape\n",
    "    print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model_init = {}\n",
    "for x in range(10):\n",
    "    if x % 3 == 0:\n",
    "        model_init[x] = resnet8(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))\n",
    "    elif x % 3 == 1:\n",
    "        model_init[x] = resnet16(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))\n",
    "    else:\n",
    "        model_init[x] = resnet20(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy init_model_parameters to model\n",
    "model = {}\n",
    "for i in range(10):\n",
    "    model[i] = copy.deepcopy(model_init[i])\n",
    "    print(\"---------------------------------model[\", i, \"]---------------------------------\")\n",
    "    print(model[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_accs_dict = {}\n",
    "inter_accs_dict = {}\n",
    "mean_intra_acc_list = []\n",
    "mean_inter_acc_list = []\n",
    "\n",
    "def _off_diagonal(x):\n",
    "     n, m = x.shape\n",
    "     assert n == m\n",
    "     return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "def _calculate_isd_sim(features):\n",
    "     sim_q = torch.mm(features, features.T)\n",
    "     # Create a mask matrix logits_mask to set the diagonal elements of the similarity matrix \n",
    "     # (i.e., the similarity between oneself and oneself) to 0, while keeping the remaining elements to 1\n",
    "     logits_mask = torch.scatter(\n",
    "          torch.ones_like(sim_q),\n",
    "          1,\n",
    "          torch.arange(sim_q.size(0)).view(-1, 1).to(args.device),\n",
    "          0\n",
    "     )\n",
    "     row_size = sim_q.size(0)                                         # The number of rows in the similarity matrix sim_q\n",
    "     sim_q = sim_q[logits_mask.bool()].view(row_size, -1)             # The similarity matrix after filtering out diagonal elements has a shape of [n, n-1]\n",
    "     return sim_q / 0.02                                              # temp = 0.02\n",
    "\n",
    "\n",
    "# copy init_model_parameters to model_inter\n",
    "model_inter = {}\n",
    "for uid in dict_users:\n",
    "     model_inter[uid] = copy.deepcopy(model_init[uid])\n",
    "\n",
    "for epoch_index in range(args.epochs):       # args.epochs\n",
    "     acc_all = []\n",
    "     \n",
    "     for batch_idx, (images, _) in enumerate(DataLoader(dataset_public, batch_size = 8)):\n",
    "          '''\n",
    "            Aggregate the output from participants\n",
    "          '''\n",
    "          batch_loss_dict = {}\n",
    "\n",
    "          linear_output_list = []                      # Store the raw output of each model\n",
    "          linear_output_target_list = []               # Store a copy of each model outpu\n",
    "          logitis_sim_list = []\n",
    "          logits_sim_target_list = []\n",
    "          images = images.to(args.device)\n",
    "          \n",
    "          for uid in dict_users:\n",
    "               model[uid] = model[uid].to(args.device)\n",
    "               model[uid].train()\n",
    "               linear_output  = model[uid](images)     # Calculate linear_output\n",
    "               linear_output_target_list.append(linear_output.clone().detach())\n",
    "               linear_output_list.append(linear_output)\n",
    "               features = model[uid].features(images)\n",
    "               features = F.normalize(features, dim = 1)\n",
    "               logits_sim = _calculate_isd_sim(features)\n",
    "               logits_sim_target_list.append(logits_sim.clone().detach())\n",
    "               logitis_sim_list.append(logits_sim)\n",
    "\n",
    "          '''\n",
    "            Update Participants' Models via Col Loss\n",
    "          '''\n",
    "          for uid in dict_users:\n",
    "               model[uid] = model[uid].to(args.device)\n",
    "               model[uid].train()\n",
    "               optimizer = torch.optim.SGD(model[uid].parameters(), lr = args.lr, momentum = args.momentum, weight_decay = 5e-4)\n",
    "\n",
    "               '''\n",
    "                 FCCM-LOSS\n",
    "               '''\n",
    "               linear_output_target_avg_list = []\n",
    "               for k in range(len(dict_users)):\n",
    "                    linear_output_target_avg_list.append(linear_output_target_list[k])\n",
    "\n",
    "               linear_output_target_avg = torch.mean(torch.stack(linear_output_target_avg_list), 0)\n",
    "               \n",
    "               linear_output = linear_output_list[uid]\n",
    "               # Perform normalization (subtract the mean and divide by the standard deviation) on the current model output z_1_bn and the average value of the target output z_2_bn\n",
    "               z_1_bn = (linear_output-linear_output.mean(0))/linear_output.std(0)\n",
    "               z_2_bn = (linear_output_target_avg-linear_output_target_avg.mean(0))/linear_output_target_avg.std(0)\n",
    "               c = z_1_bn.T @ z_2_bn\n",
    "               c.div_(len(images))\n",
    "\n",
    "               on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()               # Diagonal element close to 1\n",
    "               off_diag = _off_diagonal(c).add_(1).pow_(2).sum()                # Non diagonal elements close to 0\n",
    "               fccl_loss = on_diag + 0.0051 * off_diag\n",
    "\n",
    "               '''\n",
    "                 FISL-LOSS\n",
    "               '''\n",
    "               # Obtain the feature similarity distribution of the current network model\n",
    "               logits_sim = logitis_sim_list[uid]\n",
    "               logits_sim_target_avg_list = []\n",
    "               for k in range(len(dict_users)):\n",
    "                    logits_sim_target_avg_list.append(logits_sim_target_list[k])\n",
    "               # Calculate the average value of the characteristic similarity distribution target of all participants\n",
    "               logits_sim_target_avg = torch.mean(torch.stack(logits_sim_target_avg_list), 0)\n",
    "\n",
    "               inputs = F.log_softmax(logits_sim, dim=1)\n",
    "               targets = F.softmax(logits_sim_target_avg, dim=1)\n",
    "               loss_distill = F.kl_div(inputs, targets, reduction='batchmean')\n",
    "               loss_distill = 3 * loss_distill           # Weight of distillation loss: dis_power = 3\n",
    "\n",
    "               optimizer.zero_grad()\n",
    "               col_loss = fccl_loss + loss_distill       # Total LOSS\n",
    "               batch_loss_dict[uid] = {'fccl': round(fccl_loss.item(), 3), 'distill': round(loss_distill.item(), 3)}\n",
    "               col_loss.backward()\n",
    "               optimizer.step()\n",
    "\n",
    "     T = 3\n",
    "     for uid in dict_users:\n",
    "          model[uid] = model[uid].to(args.device)\n",
    "          model_inter[uid] = model_inter[uid].to(args.device)\n",
    "          model[uid].train()\n",
    "          model_inter[uid].train()\n",
    "          optimizer = torch.optim.SGD(model[uid].parameters(), lr = args.lr, momentum = args.momentum, weight_decay = 5e-4)\n",
    "          criterionCE = nn.CrossEntropyLoss()\n",
    "          criterionCE.to(args.device)\n",
    "          criterionKL = nn.KLDivLoss(reduction='batchmean')\n",
    "          criterionKL.to(args.device)\n",
    "          ldr_train = DataLoader(DatasetSplit(dataset_train, dict_users[uid]), batch_size = 8)\n",
    "          for _ in range(5):\n",
    "               for batch_idx, (images, labels) in enumerate(ldr_train):\n",
    "                    images = images.to(args.device)\n",
    "                    labels = labels.to(args.device)\n",
    "                    outputs = model[uid](images)\n",
    "                    bs, class_num = outputs.shape\n",
    "                    soft_outputs = F.softmax(outputs / T, dim=1)\n",
    "                    non_targets_mask = torch.ones(bs, class_num).to(args.device).scatter_(1, labels.view(-1, 1), 0)\n",
    "                    non_target_soft_outputs = soft_outputs[non_targets_mask.bool()].view(bs, class_num - 1)\n",
    "                    non_target_logsoft_outputs = torch.log(non_target_soft_outputs)\n",
    "                    with torch.no_grad():\n",
    "                         inter_outputs = model_inter[uid](images)\n",
    "                         soft_inter_outpus = F.softmax(inter_outputs / T, dim=1)\n",
    "                         # Federal non-target distillation\n",
    "                         non_target_soft_inter_outputs = soft_inter_outpus[non_targets_mask.bool()].view(bs, class_num - 1)\n",
    "\n",
    "                    inter_loss = criterionKL(non_target_logsoft_outputs, non_target_soft_inter_outputs)\n",
    "                    loss_hard = criterionCE(outputs, labels)\n",
    "                    inter_loss = inter_loss * (T ** 2)        # T = 3\n",
    "                    loss = loss_hard + inter_loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "          model_inter[uid] = copy.deepcopy(model[uid])\n",
    "          model[uid].eval()\n",
    "          acc_fine_test = test_img(model[uid], dataset_test, args)\n",
    "          acc_all.append(acc_fine_test.item())\n",
    "     print(epoch_index + 1, \":\", \"mean Fine_Test/AccTop1 on all clients:\", float(np.mean(np.array(acc_all))))\n",
    "     args.lr = args.lr * (1 - epoch_index / args.epochs * 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
