{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np   \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import hnswlib\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from utils.sampling import partition_data_dataset\n",
    "from utils.options import args_parser\n",
    "from models.Update import DatasetSplit\n",
    "from models.test import test_img\n",
    "from models.resnet_client import resnet20, resnet16, resnet8\n",
    "from torchvision.models import mobilenet_v3_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # parse args\n",
    "    args = args_parser(args=['--dataset','cinic', '--momentum','0.9', '--alpha','10', \n",
    "                                '--epochs','50', '--gpu','0', '--lr','0.01'])\n",
    "\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "    print('torch.cuda:',torch.cuda.is_available())\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and split users\n",
    "# No Public Data Partition\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if args.dataset == 'mnist':\n",
    "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda img: img.expand(3, -1, -1)), \n",
    "                                                    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))])\n",
    "        dataset_train = datasets.MNIST('data/mnist/', train = True, download = False, transform=trans_mnist)\n",
    "        dataset_test = datasets.MNIST('data/mnist/', train = False, download = False, transform=trans_mnist)\n",
    "\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "    elif args.dataset == 'fashionmnist':\n",
    "        trans_fashionmnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda img: img.expand(3, -1, -1)), \n",
    "                                                    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))])\n",
    "        dataset_train = datasets.FashionMNIST('data/fashionmnist/', train = True, download = False, transform = trans_fashionmnist)\n",
    "        dataset_test = datasets.FashionMNIST('data/fashionmnist/', train = False, download = False, transform = trans_fashionmnist)\n",
    "    \n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "    elif args.dataset == 'cifar':\n",
    "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        dataset_train = datasets.CIFAR10('data/cifar', train = True, download = False, transform = trans_cifar)\n",
    "        dataset_test = datasets.CIFAR10('data/cifar', train = False, download = False, transform = trans_cifar)\n",
    "\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "\n",
    "    elif args.dataset == 'cinic':\n",
    "        cinic_mean = [0.47889522, 0.47227842, 0.43047404]\n",
    "        cinic_std = [0.24205776, 0.23828046, 0.25874835]\n",
    "        transform_cinic = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = cinic_mean, std = cinic_std)\n",
    "        ])\n",
    "        cinic_directory = 'data/cinic'\n",
    "        dataset_train = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'train'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_valid = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'valid'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_test = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'test'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_train = torch.utils.data.ConcatDataset([dataset_train, dataset_valid])\n",
    "\n",
    "\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "\n",
    "    print(\"num_users:\", len(dict_users))\n",
    "    img_size = dataset_train[0][0].shape\n",
    "    print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model_init = {}\n",
    "acc_init_test = []\n",
    "for x in range(10):\n",
    "    if x % 3 == 0:\n",
    "        model_init[x] = resnet8(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))\n",
    "    elif x % 3 == 1:\n",
    "        model_init[x] = resnet16(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))\n",
    "    else:\n",
    "        model_init[x] = resnet20(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))\n",
    "    acc_init_test.append(acc_test.item())\n",
    "print(\"mean AccTop1 on all clients:\",float(np.mean(np.array(acc_init_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy init_model_parameters\n",
    "model = {}\n",
    "for i in range(10):\n",
    "    model[i] = copy.deepcopy(model_init[i])\n",
    "    print(\"---------------------------------model[\", i, \"]---------------------------------\")\n",
    "    print(model[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeCache:\n",
    "    def __init__(self,n_classes, R):\n",
    "        self.n_classes=n_classes\n",
    "        self.cache={}\n",
    "        self.idx_to_hash={}\n",
    "        self.relation={}\n",
    "        for i in range(n_classes):\n",
    "            self.cache[i]={}\n",
    "        self.R = R\n",
    "        pass\n",
    "\n",
    "    def add_hash(self, hash, label,idx):\n",
    "        for k_,l_,i_ in zip(hash, label, idx):\n",
    "            self.add_hash_single(k_, l_, i_)\n",
    "\n",
    "    def add_hash_single(self,hash,label,idx):\n",
    "        self.cache[int(label)][idx]=torch.Tensor(np.array([0.0 for _ in range(self.n_classes)]))\n",
    "        self.idx_to_hash[idx] = hash\n",
    "\n",
    "    # Approximate nearest neighbor search (ANN) finds semantically similar neighbors for each data sample\n",
    "    def build_relation(self):\n",
    "        hnsw_sim = 0\n",
    "        for c in range(self.n_classes):\n",
    "            idx_vectors=[key for key in self.cache[c].keys()]\n",
    "            data = list()\n",
    "            data=np.array([self.idx_to_hash[key].numpy() for key in idx_vectors])\n",
    "            num_elements = data.shape[0]\n",
    "            dim = data.shape[1]\n",
    "            data_labels = np.arange(num_elements)\n",
    "            index = hnswlib.Index(space='cosine', dim=dim)\n",
    "            index.init_index(max_elements=num_elements, ef_construction = 1000, M = 64)\n",
    "            index.add_items(data, data_labels)\n",
    "            index.set_ef(1000)\n",
    "            labels, distances = index.knn_query(data, self.R+1)\n",
    "            for idx,ele in enumerate(labels):\n",
    "                self.relation[idx_vectors[int(idx)]]=[]\n",
    "                for x in ele[1:]:\n",
    "                    self.relation[idx_vectors[int(idx)]].append(idx_vectors[x])\n",
    "\n",
    "    def set_knowledge(self,knowledge,label,idx):\n",
    "        for k_, l_, i_ in zip(knowledge,label,idx):\n",
    "            self.set_knowledge_single(k_, l_, i_)\n",
    "\n",
    "    def set_knowledge_single(self,knowledge,label,idx):\n",
    "        self.cache[int(label)][idx]=knowledge\n",
    "\n",
    "    def fetch_knowledge(self,label,idx):\n",
    "        result = []\n",
    "        for l_,i_ in zip(label,idx):\n",
    "            result.append(self.fetch_knowledge_single(l_, i_))\n",
    "        return result\n",
    "\n",
    "    def fetch_knowledge_single(self, label, idx):\n",
    "        result = []\n",
    "        pairs=self.relation[idx]\n",
    "        for pair in pairs:\n",
    "            result.append(self.cache[int(label)][pair])\n",
    "        return result\n",
    "\n",
    "def knowledge_avg_single(knowledge, weights):\n",
    "    result=torch.zeros_like(knowledge[0]).cpu()\n",
    "    sum = 0\n",
    "    for _k,_w in zip(knowledge,weights):\n",
    "        result.add_(_k.cpu()*_w)\n",
    "        sum = sum+_w\n",
    "    result = result / sum\n",
    "    return torch.tensor(np.array(result.detach().cpu()))\n",
    "\n",
    "class KL_Loss(nn.Module):\n",
    "    def __init__(self, temperature = 3.0):\n",
    "        super(KL_Loss, self).__init__()\n",
    "        self.T = temperature\n",
    "\n",
    "    def forward(self, output_batch, teacher_outputs):\n",
    "        output_batch = F.log_softmax(output_batch / self.T, dim = 1)\n",
    "        teacher_outputs = F.softmax(teacher_outputs / self.T, dim = 1) + 10 ** (-7)\n",
    "        loss = self.T * self.T * nn.KLDivLoss(reduction = 'batchmean')(output_batch, teacher_outputs)\n",
    "        return loss\n",
    "\n",
    "image_scaler = transforms.Compose([transforms.Resize(224),])\n",
    "criterion_KL = KL_Loss()\n",
    "print(\"*********start training with FedCache***************\")\n",
    "train_data_local_dict_seq = {}\n",
    "for client_index in range(len(dict_users)):\n",
    "    train_data_local_dict_seq[client_index] = []\n",
    "    for batch_idx, (images, labels) in enumerate(DataLoader(DatasetSplit(dataset_train, dict_users[client_index]), batch_size = 256)):\n",
    "        train_data_local_dict_seq[client_index].append((images, labels))\n",
    "knowledge_cache = KnowledgeCache(10, 16)                # class_num = 10\n",
    "encoder = mobilenet_v3_small(weights='IMAGENET1K_V1').to(args.device)\n",
    "encoder = torch.nn.Sequential( *( list(encoder.children())[:-1] ) )\n",
    "encoder.eval()\n",
    "for client_index in range(len(dict_users)):\n",
    "    cur_idx = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_data_local_dict_seq[client_index]):\n",
    "        images, labels = images.to(args.device), labels.to(args.device)\n",
    "        hash_code = encoder(image_scaler(images)).detach().cpu()\n",
    "        hash_code = torch.tensor(hash_code.reshape((hash_code.shape[0],hash_code.shape[1])))\n",
    "        for img, hash, label in zip(images, hash_code, labels):\n",
    "            knowledge_cache.add_hash_single(hash, label, (client_index, cur_idx))\n",
    "            cur_idx = cur_idx + 1\n",
    "knowledge_cache.build_relation()\n",
    "print(\"*********knowledge cache initialized successfully***************\")\n",
    "for global_epoch in range(args.epochs):\n",
    "    acc_all=[]\n",
    "    print(\"*********communication round\", global_epoch, \"***************\")\n",
    "    for client_index in range(len(dict_users)):\n",
    "        model[client_index].to(args.device)\n",
    "        model[client_index].train()\n",
    "        optim=torch.optim.SGD(model[client_index].parameters(), lr = args.lr, momentum = 0.9, weight_decay = 5e-4)\n",
    "        cur_idx = 0\n",
    "        for batch_idx, (images, labels) in enumerate(train_data_local_dict_seq[client_index]):\n",
    "            labels = torch.tensor(labels, dtype = torch.long)\n",
    "            images, labels = images.to(args.device), labels.to(args.device)\n",
    "            \n",
    "            log_probs = model[client_index](images)\n",
    "            loss_true = F.cross_entropy(log_probs, labels)\n",
    "            loss = None\n",
    "            \n",
    "            teacher_knowledge=[]\n",
    "            for img, logit, label in zip(images, log_probs, labels):\n",
    "                fetched_knowledge_single = knowledge_cache.fetch_knowledge_single(label, (client_index, cur_idx))\n",
    "                knowledge_cache.set_knowledge_single(logit, label, (client_index, cur_idx))\n",
    "                cur_idx = cur_idx + 1\n",
    "                avg_knowledge_single = knowledge_avg_single(fetched_knowledge_single, [1 for _ in range(16)])\n",
    "                teacher_knowledge.append(avg_knowledge_single.detach().cpu().numpy())\n",
    "            teacher_knowledge = torch.tensor(np.array(teacher_knowledge)).to(args.device)\n",
    "            loss_kd = criterion_KL(log_probs, teacher_knowledge / 1.0)\n",
    "            loss = loss_true + 1.5 * loss_kd\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        model[client_index].eval()\n",
    "        acc_fine_test = test_img(model[client_index], dataset_test, args)\n",
    "        acc_all.append(acc_fine_test.item())\n",
    "    print(\"communication round:\", global_epoch, \"mean Fine_Test/AccTop1 on all clients:\", float(np.mean(np.array(acc_all))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
