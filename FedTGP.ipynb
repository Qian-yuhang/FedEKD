{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np   \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from utils.sampling import partition_data_dataset\n",
    "from utils.options import args_parser\n",
    "from models.Update import DatasetSplit\n",
    "from models.test import test_img\n",
    "from models.resnet_client import resnet20, resnet16, resnet8\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # parse args\n",
    "    args = args_parser(args=['--dataset','cinic', '--momentum','0.9', '--alpha','5',\n",
    "                             '--epochs','50', '--gpu','0', '--lr','0.01'])\n",
    "\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "    print('torch.cuda:',torch.cuda.is_available())\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4618ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and split users\n",
    "# No Public Data Partition\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if args.dataset == 'mnist':\n",
    "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda img: img.expand(3, -1, -1)), \n",
    "                                                    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))])\n",
    "        dataset_train = datasets.MNIST('data/mnist/', train = True, download = False, transform = trans_mnist)\n",
    "        dataset_test = datasets.MNIST('data/mnist/', train = False, download = False, transform = trans_mnist)\n",
    "\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])                     # 记录标签 array 数组\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "    elif args.dataset == 'fashionmnist':\n",
    "        trans_fashionmnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda img: img.expand(3, -1, -1)), \n",
    "                                                    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))])\n",
    "        dataset_train = datasets.FashionMNIST('data/fashionmnist/', train = True, download = False, transform = trans_fashionmnist)\n",
    "        dataset_test = datasets.FashionMNIST('data/fashionmnist/', train = False, download = False, transform = trans_fashionmnist)\n",
    "    \n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "    elif args.dataset == 'cifar':\n",
    "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        dataset_train = datasets.CIFAR10('data/cifar', train = True, download = False, transform = trans_cifar)\n",
    "        dataset_test = datasets.CIFAR10('data/cifar', train = False, download = False, transform = trans_cifar)\n",
    "\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "\n",
    "    elif args.dataset == 'cinic':\n",
    "        cinic_mean = [0.47889522, 0.47227842, 0.43047404]\n",
    "        cinic_std = [0.24205776, 0.23828046, 0.25874835]\n",
    "        transform_cinic = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cinic_mean, std=cinic_std)\n",
    "        ])\n",
    "        cinic_directory = 'data/cinic'\n",
    "        dataset_train = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'train'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_valid = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'valid'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_test = datasets.ImageFolder(\n",
    "            os.path.join(cinic_directory, 'test'),\n",
    "            transform=transform_cinic\n",
    "        )\n",
    "        dataset_train = torch.utils.data.ConcatDataset([dataset_train, dataset_valid])\n",
    "\n",
    "        print('len(dataset_train): ', len(dataset_train))\n",
    "        print('len(dataset_test): ', len(dataset_test))\n",
    "        \n",
    "        dataset_train_labels = np.array([])\n",
    "        for i,(x, y) in enumerate(dataset_train):\n",
    "            dataset_train_labels = np.append(dataset_train_labels, y)\n",
    "        dataset_train_labels = dataset_train_labels.astype(int)\n",
    "\n",
    "        dict_users = partition_data_dataset(dataset_train_labels, 10, alpha = args.alpha)\n",
    "\n",
    "\n",
    "    print(\"num_users:\", len(dict_users))\n",
    "    img_size = dataset_train[0][0].shape\n",
    "    print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model_init = {}\n",
    "for x in range(10):\n",
    "    if x % 3 == 0:\n",
    "        model_init[x] = resnet8(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))\n",
    "    elif x % 3 == 1:\n",
    "        model_init[x] = resnet16(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))\n",
    "    else:\n",
    "        model_init[x] = resnet20(10).to(args.device)\n",
    "        model_init[x].eval()\n",
    "        acc_test = test_img(model_init[x], dataset_test, args)\n",
    "        print(\"user-uid:\", x, \"init_Local_Training_accuracy: {:.2f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b512a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy init_model_parameters to model\n",
    "model = {}\n",
    "for i in range(10):\n",
    "    model[i] = copy.deepcopy(model_init[i])\n",
    "    print(\"---------------------------------model[\", i, \"]---------------------------------\")\n",
    "    print(model[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5546814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainable_Global_Prototypes(nn.Module):\n",
    "    def __init__(self, num_classes, server_hidden_dim, feature_dim, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.embedings = nn.Embedding(num_classes, feature_dim)\n",
    "        layers = [nn.Sequential(\n",
    "            nn.Linear(feature_dim, server_hidden_dim), \n",
    "            nn.ReLU()\n",
    "        )]\n",
    "        self.middle = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(server_hidden_dim, feature_dim)\n",
    "\n",
    "    def forward(self, class_id):\n",
    "        class_id = torch.tensor(class_id, device=self.device)\n",
    "\n",
    "        emb = self.embedings(class_id)\n",
    "        mid = self.middle(emb)\n",
    "        out = self.fc(mid)\n",
    "\n",
    "        return out\n",
    "\n",
    "TGP = Trainable_Global_Prototypes(args.num_classes, 256, 256, args.device).to(args.device)\n",
    "print(TGP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2532f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_protos = []\n",
    "\n",
    "def agg_func(protos):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "\n",
    "    for [label, proto_list] in protos.items():\n",
    "        if len(proto_list) > 1:\n",
    "            proto = 0 * proto_list[0].data\n",
    "            for i in proto_list:\n",
    "                proto += i.data\n",
    "            protos[label] = proto / len(proto_list)\n",
    "        else:\n",
    "            protos[label] = proto_list[0]\n",
    "\n",
    "    return protos\n",
    "\n",
    "def proto_cluster(protos_list):\n",
    "    proto_clusters = defaultdict(list)\n",
    "    for protos in protos_list:\n",
    "        for k in protos.keys():\n",
    "            proto_clusters[k].append(protos[k])\n",
    "\n",
    "    for k in proto_clusters.keys():\n",
    "        protos = torch.stack(proto_clusters[k])\n",
    "        proto_clusters[k] = torch.mean(protos, dim = 0).detach()\n",
    "\n",
    "    return proto_clusters\n",
    "\n",
    "\n",
    "for epoch_index in range(args.epochs):\n",
    "    # print(f'\\n | Global Training Round : {epoch_index + 1} |\\n')\n",
    "    acc_all = []\n",
    "    local_protos = {}\n",
    "    for idx in range(len(dict_users)):\n",
    "        model[idx].train()\n",
    "        optimizer = torch.optim.SGD(model[idx].parameters(), lr = args.lr, momentum = args.momentum, weight_decay = 5e-4)\n",
    "        ldr_train = DataLoader(DatasetSplit(dataset_train, dict_users[idx]), batch_size = 8, shuffle = True)\n",
    "        criterionCE = nn.CrossEntropyLoss()\n",
    "        for iter in range(1):\n",
    "            for batch_idx, (images, label_g) in enumerate(ldr_train):\n",
    "                images, labels = images.to(args.device), label_g.to(args.device)\n",
    "                model[idx].zero_grad()\n",
    "                log_probs = model[idx](images)\n",
    "                rep = model[idx].features(images)\n",
    "                loss = criterionCE(log_probs, labels)\n",
    "                \n",
    "                loss_mse = nn.MSELoss()\n",
    "                if len(global_protos) == 0:\n",
    "                    loss2 = 0 * loss\n",
    "                else:\n",
    "                    proto_new = copy.deepcopy(rep.detach())\n",
    "                    for i, yy in enumerate(label_g):\n",
    "                        y_c = yy.item()\n",
    "                        if type(global_protos[y_c]) != type([]):\n",
    "                            proto_new[i, :] = global_protos[y_c].data\n",
    "                    loss += loss_mse(proto_new, rep) * 0.1                        # 1 for mnist/fashionmnist    &&     0.1 for cifar/cinic\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        # collect protos\n",
    "        model[idx].eval()\n",
    "        protos = defaultdict(list)\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(ldr_train):\n",
    "                if type(x) == type([]):\n",
    "                    x[0] = x[0].to(args.device)\n",
    "                else:\n",
    "                    x = x.to(args.device)\n",
    "                y = y.to(args.device)\n",
    "                rep = model[idx].features(x)\n",
    "\n",
    "                for i, yy in enumerate(y):\n",
    "                    y_c = yy.item()\n",
    "                    protos[y_c].append(rep[i, :].detach().data)\n",
    "        local_protos[idx] = agg_func(protos)\n",
    "        \n",
    "    uploaded_protos = []\n",
    "    uploaded_protos_per_client = []\n",
    "    for client_id in local_protos:\n",
    "        protos = local_protos[client_id]\n",
    "        for k in protos.keys():\n",
    "            uploaded_protos.append((protos[k], k))\n",
    "        uploaded_protos_per_client.append(protos)\n",
    "    \n",
    "    # calculate class-wise minimum distance\n",
    "    gap = torch.ones(args.num_classes, device = args.device) * 1e9\n",
    "    avg_protos = proto_cluster(uploaded_protos_per_client)\n",
    "    for k1 in avg_protos.keys():\n",
    "        for k2 in avg_protos.keys():\n",
    "            if k1 > k2:\n",
    "                dis = torch.norm(avg_protos[k1] - avg_protos[k2], p  = 2)\n",
    "                gap[k1] = torch.min(gap[k1], dis)\n",
    "                gap[k2] = torch.min(gap[k2], dis)\n",
    "    min_gap = torch.min(gap)\n",
    "    for i in range(len(gap)):\n",
    "        if gap[i] > torch.tensor(1e8, device = args.device):\n",
    "            gap[i] = min_gap\n",
    "    max_gap = torch.max(gap)\n",
    "    # print('class-wise minimum distance', gap)\n",
    "    # print('min_gap', min_gap)\n",
    "    # print('max_gap', max_gap)\n",
    "    TGP_opt = torch.optim.SGD(TGP.parameters(), lr = 0.005)\n",
    "    TGP.train()\n",
    "    server_epochs = 100\n",
    "    CEloss = nn.CrossEntropyLoss()\n",
    "    for e in range(server_epochs):\n",
    "        proto_loader = DataLoader(uploaded_protos, 8, shuffle = True)\n",
    "        for proto, y in proto_loader:\n",
    "            y = torch.Tensor(y).type(torch.int64).to(args.device)\n",
    "\n",
    "            proto_gen = TGP(list(range(args.num_classes)))\n",
    "\n",
    "            features_square = torch.sum(torch.pow(proto, 2), 1, keepdim = True)\n",
    "            centers_square = torch.sum(torch.pow(proto_gen, 2), 1, keepdim = True)\n",
    "            features_into_centers = torch.matmul(proto, proto_gen.T)\n",
    "            dist = features_square - 2 * features_into_centers + centers_square.T\n",
    "            dist = torch.sqrt(dist)\n",
    "                \n",
    "            one_hot = F.one_hot(y, args.num_classes).to(args.device)\n",
    "            margin = min(max_gap.item(), 100)           # margin_threthold = 100\n",
    "            dist = dist + one_hot * margin\n",
    "            loss = CEloss(-dist, y)\n",
    "\n",
    "            TGP_opt.zero_grad()\n",
    "            loss.backward()\n",
    "            TGP_opt.step()\n",
    "\n",
    "    uploaded_protos = []\n",
    "\n",
    "    TGP.eval()\n",
    "    global_protos = defaultdict(list)\n",
    "    for class_id in range(args.num_classes):\n",
    "        global_protos[class_id] = TGP(torch.tensor(class_id, device=args.device)).detach()\n",
    "    \n",
    "    for idx in range(len(dict_users)):\n",
    "        model[idx].eval()\n",
    "        acc_fine_test = test_img(model[idx], dataset_test, args)\n",
    "        # print(\"round:\", epoch_index,\"idx:\", idx, \"Train Testing accuracy: {:.2f}\".format(acc_fine_test))\n",
    "        acc_all.append(acc_fine_test.item())\n",
    "        \n",
    "    print(epoch_index + 1, \":\", \"mean Fine_Test/AccTop1 on all clients:\", float(np.mean(np.array(acc_all))))\n",
    "    args.lr = args.lr * (1 - epoch_index / args.epochs * 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
